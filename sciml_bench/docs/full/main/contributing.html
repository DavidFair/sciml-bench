<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>Contributing Benchmarks and Datasets - </title>
        <link href="../css/bootstrap.min.css" rel="stylesheet">
        <link href="../css/font-awesome.min.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css">

        <script src="../js/jquery-1.10.2.min.js" defer></script>
        <script src="../js/bootstrap.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="../index.html"></a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="navitem">
                                <a href="../index.html" class="nav-link">SciML-Bench Documentation (Version 1.1.0.b110721_2342)</a>
                            </li>
                            <li class="navitem">
                                <a href="../credits.html" class="nav-link">SciML Benchmark Suite - Credits</a>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Benchmarks <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../benchmarks/dms_structure.html" class="dropdown-item">dms_structure Benchmark</a>
</li>
                                    
<li>
    <a href="../benchmarks/em_denoise.html" class="dropdown-item">em-denoise Benchmark</a>
</li>
                                    
<li>
    <a href="../benchmarks/slstr_cloud.html" class="dropdown-item">slstr_cloud Benchmark</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Datasets <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../datasets/cloud_slstr_ds1.html" class="dropdown-item">Cloud slstr ds1</a>
</li>
                                    
<li>
    <a href="../datasets/dms_sim.html" class="dropdown-item">Dms sim</a>
</li>
                                    
<li>
    <a href="../datasets/em_graphene_sim.html" class="dropdown-item">em_graphene_sim</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown active">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Main <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="api.html" class="dropdown-item">SciML-Bench API</a>
</li>
                                    
<li>
    <a href="configuration.html" class="dropdown-item">Configuration Options</a>
</li>
                                    
<li>
    <a href="contributing.html" class="dropdown-item active">Contributing Benchmarks and Datasets</a>
</li>
                                    
<li>
    <a href="faq.html" class="dropdown-item">Frequently Asked Questions</a>
</li>
                                    
<li>
    <a href="installation.html" class="dropdown-item">Installation</a>
</li>
                                    
<li>
    <a href="intro.html" class="dropdown-item">Intro</a>
</li>
                                    
<li>
    <a href="usage.html" class="dropdown-item">Using the Suite and Benchmarks</a>
</li>
                                </ul>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ml-auto">
                            <li class="nav-item">
                                <a rel="prev" href="configuration.html" class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" href="faq.html" class="nav-link">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-level="1"><a href="#contributing-benchmarks-and-datasets" class="nav-link">Contributing Benchmarks and Datasets</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#1-introduction" class="nav-link">1. Introduction</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#setting-up-the-environment" class="nav-link">Setting up the Environment</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#2-the-configuration-file" class="nav-link">2.  The Configuration File</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#3-developing-benchmarks" class="nav-link">3. Developing Benchmarks</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#4-contributing-benchmarks" class="nav-link">4. Contributing Benchmarks</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
            
            <li class="nav-item" data-level="1"><a href="#5-contributing-datsets" class="nav-link">5. Contributing Datsets</a>
              <ul class="nav flex-column">
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<h1 id="contributing-benchmarks-and-datasets">Contributing Benchmarks and Datasets</h1>
<p><br></p>
<h2 id="1-introduction">1. Introduction</h2>
<p>This page/file is intended to help you contribute to the SciML benchmarking initiatives. The contributions can be in different forms, from providing fully-fledged benchmarks to datasets to providing comments and suggestions to improve the benchmark suite. Although majority of this page is focused on enabling you to contribute towards new benchmarks, we have outlined the general ways to contribute to the SciML Bench suite in latter part of this document. </p>
<h2 id="setting-up-the-environment">Setting up the Environment</h2>
<ul>
<li>
<p>Make sure that you are familiar with the notion of benchmarking, particularly, what benchmarks mean in the context of SciML-Bench, and the installation of the suite. </p>
</li>
<li>
<p>As a contributor, you can launch the command-line interface (CLI) in a number of ways to facilitate the development,  For example, from the repository folder,  </p>
<p><code>sh
python -m sciml_bench.core.command --help</code></p>
</li>
</ul>
<p>where <code>sciml_bench.core.command</code> is the entry point of <code>sciml-bench</code>  after installation with <code>pip</code>. </p>
<p>This way, any local changes to the repository will be visible to the CLI, avoiding unnecessary      re-installations.</p>
<p>â€‹  <br />
<br></p>
<h2 id="2-the-configuration-file">2.  The Configuration File</h2>
<p>As outlined in the main README file, a single benchmark in SciML-Bench includes two key elements, namely, (one or more) dataset(s), and a reference implementation in Python that solves a particular scientific problem.  We carefully curate the benchmarks (and relevant datasets) included in every release. </p>
<p>The association between benchmarks and datasets is, as outlined before, is many-to-many. These relationships, relevant dependencies,  exact location of the datasets, and download methods (if any) are maintained in a single configuration file <code>etc/configs</code> folder. We recommend you to read the <a href="configurations.md">Configuration File</a> section. </p>
<p>During the development phase, the datasets do not have to  be deposited  in STFC servers.  Instead, they can be maintained at a location of your choice, for example a local directory. If datasets are locally stored, the <code>download</code> method can be left empty (or ignored), and instead the directory can be specified using the <code>--dataset_dir</code> option when launching the <code>sciml-bench run</code>.  By default, for all the benchmarks distributed by us, the datasets are maintained in the STFC servers (or its mirrors),  and you do not have to modify the download command. </p>
<p><br></p>
<h2 id="3-developing-benchmarks">3. Developing Benchmarks</h2>
<p>Each benchmark inside SciML-Bench must meet the minimum requirements outlined in the <a href="api.html">API</a> document. In addition to this documentation, we have also provided a number of examples in the suite, which can be found inside the <code>benchmarks/examples</code> folder.  Developing a benchmark involves two main aspects: </p>
<ol>
<li>Implementation of the benchmark, and </li>
<li>Dataset(s) on which the implementation operates. </li>
</ol>
<p>We cover these two in the sections that follow this.</p>
<p><br></p>
<h2 id="4-contributing-benchmarks">4. Contributing Benchmarks</h2>
<p>The scope of a single benchmark can be manyfold. However, in our case, a benchmark must meet the following criteria:</p>
<ol>
<li>It must focus on a (ideally) practically significant scientific problem,</li>
<li>It should (ideally) use a machine learning technique to solve the problem in (1),</li>
<li>There is a clear and domain-specific metric to measure the outcome of the benchmarking exercise, and</li>
<li>There is a real or simulated dataset on which the benchmark operates. </li>
</ol>
<p>The contribution may come from any domain and can use any amount of data, but ideally on large (and open datasets). The aim here is to foster scientific development and growth than purely measuring performance (which, in fact, an interesting outcome).</p>
<p>The following are basic requirements when contributing a benchmark towards the SciML-Bench:</p>
<ol>
<li>The code should be openly available without any form of restrictive licensing model. Ideally, we would promote MIT or BSD-style license models.</li>
<li>A Python-based implementation, strictly relying on Python 3+ and using one of the machine learning frameworks, like PyTorch, TensorFlow, MXNet and alike. Although we would encourage multiple implementations (covering each framework), it is not necessary. </li>
<li>The implementation should at least focus on training or inference (or both). Depending on the focus of the benchmark, it has to include the implementations for  <code>sciml_bench_training()</code> and/or <code>sciml_bench_inference()</code>.</li>
<li>A clear documentation on the benchmark, outlining the primary domain where the problem comes from (such as material sciences, astronomy, particle physics, environmental sciences, earth sciences and alike), sub-domain of the problem, the intended learning task (estimation, classification etc), relevant datasets.</li>
<li>List of authors who contributed to the development / implementation of the benchmark.</li>
</ol>
<p>There are best practices of how benchmarks should be implemented, but examples supplied with the suite are sufficient enough to learn these. Some of these are worth stating here:</p>
<ol>
<li>Although there is nothing wrong with an implementation based on a single file, it is better to modularise the implementation, say using multiple files, as needed. </li>
<li>Always use lower-case for benchmark names to avoid platform-specific issues. </li>
<li>Consider the dependencies and libraries you are using. If the benchmark has complex dependencies and tends to be difficult for an average user to install, please reconsider this. In reality, if it is difficult to install, it is very unlikely that end users will use it. </li>
</ol>
<p>If you are contributing towards an existing case, follow the same set of rules, except that you provide this as one of the baselines. As such, the existing benchmarking code has to be modified.</p>
<p><br></p>
<h1 id="5-contributing-datsets">5. Contributing Datsets</h1>
<p>Benchmarks operate on one or more datasets. As such, each benchmark should be accompanied with the relevant datasets.  The following are basic requirements when contributing a dataset towards the SciML-Bench:</p>
<ol>
<li>The dataset(s) should be openly available without any form of restrictive licensing model. Ideally, we would promote MIT or BSD-style license models.</li>
<li>It should have a very clear and known data source (even if simulated) </li>
<li>A clear documentation on the dataset, outlining the primary domain where the dataset comes from (such as material sciences, astronomy, particle physics, environmental sciences, earth sciences and alike), sub-domain of the dataset, data type (image, text, mixed, sound etc), and data size (in GB or TB).</li>
<li>A Python-based implementation to read or process the dataset.</li>
<li>List of authors who contributed to the dataset.</li>
</ol>
<p>The dataset can be a pre-published one, but must be open. </p></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../js/base.js" defer></script>

        <div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
